<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="indexstyle.css">
    <title>AI Sentience</title>
  </head>
  <body>
    <div class="indexdiv">
      <p>In a world where we're able to create -- or at the very least completely realistically imitate -- human sentience using artificial intelligence, we'd be able to learn a lot. Sentient Computation would be an incredible step in research and biological simulation. But even in this hypothetical reality, would Sentient Artificial Intelligence even be necessary?
	<br><br>
      <p>Artificial Intelligence is any software that can take in input and analyze the best ouput to generate based on the data it was trained on. This sounds simple, but has already proved itself to be a necessary part of our everyday society. Search engines, self driving cars, autocorrect, navigation, all these systems use Artificial Intelligence to better individual user experience. It can accurately and fluently replicate human speech, as well as generate conversations. Things like these make many people incorrectly believe Artificial Intelligence already have a level of sentience or consciousness -- that because they can seemingly make decisions, that they think, but of course it's not. Artificial Intelligence learns patterns and how systems interact with each other, it's not so much that chatbots are deciding what to say, but instead they're calculating what to say.
	<br><br>
	So AI can already provide a human-like user interface, but many believe that more advanced tasks would require human sentience in order to perform, but that isn't at all the case. Every year, more and more once "human only" activities are automated using Artificial Intelligence. One example quickly gaining attention is OpenAI's Dall-E 2, a text to image program that takes user input and generates high quality, coherent imagery. The point is, even incredibly human tasks can be completed using advanced non-sentient Artificial Intelligence. Hypothetically, non-sentient Artificial Intelligence could do any task as long as it's given the right training data and a highly capable programmer, right?
	<br><br>
	We're reaching a point where Artificial Intelligence development won't even need human programming to get it to work. Artificial Intelligence that can improve it's own code is quickly becoming an apparent reality. In fact, it's to the point where it's becoming a genuine concern that it's improvement rate will end up exponentially increasing to the point where it's incomprehensible to humans.
	<br><br>
	What's the point I'm getting at? Artificial Intelligence can already be so advanced to the point beyond human comprehension, it's already capable of doing tasks once thought to be only doable by humans, and providing comfortable life-like user experiences to users. Why would it ever need to be sentient? If we can run plumbing and electrical grids, make life altering decisions, control military missiles, and infinitley more using non-sentient artificial intelligence, what is the point of giving it the ability to be aware?
	<br><br>
	The only thing stopping the AI systems we've placed in our world from being our own downfall is one simple fact: It can't do anything more than it was trained to do. It can't think, or genuinely decide what to do, it just calculates the input it's given and relays an output. Introducing sentience, even putting the incredibly skewed and concering ethics of that aside, puts all of that up to risk. Why should systems have to decide anything when it can already produce near-perfect outcomes? Why do we need to be talking to something that can actually be aware of us, when we already have programs that can make us believe we're speaking to another human? It's a waste of technological development, and only opens the door to machine learning being able to do more than it was taught. I'm not attempting to imply the possible future of a dystopian AI takeover, but it honestly just seems genuinely redundant (if not cruel) to make our machines be conscious and aware.
	<br><br>
	I can understand the interest in conscious and sentient softwawre, but in the end it's just stopping us from making genuine steps forward in machine learning software. Artificial Intelligence doesn't need to be aware of what it's doing in order to do it, and it would be an ethically terrible decision to even try. Let the people be people. Let the machine learning systems just do what they were designed to do. Nothing more, nothing less.</p>
    </div>
  </body>
</html>
